{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfabadb8-5935-45ff-b39c-db7a29012129",
   "metadata": {
    "id": "bfabadb8-5935-45ff-b39c-db7a29012129"
   },
   "source": [
    "# Chapter 6: Finetuning for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "9495f150-9d79-4910-d6e7-6c0d9aae4a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.1\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.5.1\n",
      "tensorflow version: 2.10.0\n",
      "pandas version: 2.3.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",  # Plotting library\n",
    "        \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "        \"tiktoken\",    # Tokenizer\n",
    "        \"torch\",       # Deep learning library\n",
    "        \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "        \"pandas\"       # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/chapter-overview.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c",
   "metadata": {
    "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c"
   },
   "source": [
    "## 6.1 Different categories of finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3d731-5123-4f02-accd-c670ce50a5a3",
   "metadata": {
    "id": "ede3d731-5123-4f02-accd-c670ce50a5a3"
   },
   "source": [
    "- No code in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45579d-d485-47dc-829e-43be7f4db57b",
   "metadata": {},
   "source": [
    "- The most common ways to finetune language models are instruction-finetuning and classification finetuning\n",
    "- Instruction-finetuning, depicted below, is the topic of the next chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/instructions.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd",
   "metadata": {},
   "source": [
    "- Classification finetuning, the topic of this chapter, is a procedure you may already be familiar with if you have a background in machine learning -- it's similar to training a convolutional network to classify handwritten digits, for example\n",
    "- In classification finetuning, we have a specific number of class labels (for example, \"spam\" and \"not spam\") that the model can output\n",
    "- A classification finetuned model can only predict classes it has seen during training (for example, \"spam\" or \"not spam\"), whereas an instruction-finetuned model can usually perform many tasks\n",
    "- We can think of a classification-finetuned model as a very specialized model; in practice, it is much easier to create a specialized model than a generalist model that performs well on many different tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/spam-non-spam.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## 6.2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-1.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d",
   "metadata": {
    "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d"
   },
   "source": [
    "- This section prepares the dataset we use for classification finetuning\n",
    "- We use a dataset consisting of spam and non-spam text messages to finetune the LLM to classify them\n",
    "- First, we download and unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "424e4423-f623-443c-ab9e-656f9e867559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as sms_spam_collection\\SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\" \n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1",
   "metadata": {
    "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1"
   },
   "source": [
    "- The dataset is saved as a tab-separated text file, which we can load into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
    "outputId": "a16c5cde-d341-4887-a93f-baa9bec542ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ã¼ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will Ã¼ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109",
   "metadata": {
    "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109"
   },
   "source": [
    "- When we check the class distribution, we see that the data contains \"ham\" (i.e., \"not spam\") much more frequently than \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
    "outputId": "761e0482-43ba-4f46-f4b7-6774dae51b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773f054-0bdc-4aad-bbf6-397621bf63db",
   "metadata": {
    "id": "f773f054-0bdc-4aad-bbf6-397621bf63db"
   },
   "source": [
    "- For simplicity, and because we prefer a small dataset for educational purposes anyway (it will make it possible to finetune the LLM faster), we subsample (undersample) the dataset so that it contains 747 instances from each class\n",
    "- (Next to undersampling, there are several other ways to deal with class balances, but they are out of the scope of a book on LLMs; you can find examples and more information in the [`imbalanced-learn` user guide](https://imbalanced-learn.org/stable/user_guide.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be4a0a2-9704-4a96-b38f-240339818688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7be4a0a2-9704-4a96-b38f-240339818688",
    "outputId": "396dc415-cb71-4a88-e85d-d88201c6d73f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6",
   "metadata": {
    "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6"
   },
   "source": [
    "- Next, we change the string class labels \"ham\" and \"spam\" into integer class labels 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
   "metadata": {
    "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
   },
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f",
   "metadata": {
    "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f"
   },
   "source": [
    "- Let's now define a function that randomly divides the dataset into training, validation, and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7af0774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "uQl0Psdmx15D",
   "metadata": {
    "id": "uQl0Psdmx15D"
   },
   "outputs": [],
   "source": [
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094",
   "metadata": {},
   "source": [
    "## 6.3 Creating data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c",
   "metadata": {
    "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c"
   },
   "source": [
    "- Note that the text messages have different lengths; if we want to combine multiple training examples in a batch, we have to either\n",
    "  1. truncate all messages to the length of the shortest message in the dataset or batch\n",
    "  2. pad all messages to the length of the longest message in the dataset or batch\n",
    "\n",
    "- We choose option 2 and pad all messages to the longest message in the dataset\n",
    "- For that, we use `<|endoftext|>` as a padding token, as discussed in chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829f33f-1428-4f22-9886-7fee633b3666",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/pad-input-sequences.webp?123\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
    "outputId": "b5b48439-32c8-4b37-cca2-c9dc8fa86563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f582ff-68bf-450e-bd87-5fb61afe431c",
   "metadata": {
    "id": "04f582ff-68bf-450e-bd87-5fb61afe431c"
   },
   "source": [
    "- The `SpamDataset` class below identifies the longest sequence in the training dataset and adds the padding token to the others to match that sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
   "metadata": {
    "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "        # Note: A more pythonic version to implement this method\n",
    "        # is the following, which is also used in the next chapter:\n",
    "        # return max(len(encoded_text) for encoded_text in self.encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "uzj85f8ou82h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzj85f8ou82h",
    "outputId": "d08f1cf0-c24d-445f-a3f8-793532c3716f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60",
   "metadata": {},
   "source": [
    "- We also pad the validation and test set to the longest training sequence\n",
    "- Note that validation and test set samples that are longer than the longest training example are being truncated via `encoded_text[:self.max_length]` in the `SpamDataset` code\n",
    "- This behavior is entirely optional, and it would also work well if we set `max_length=None` in both the validation and test set cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
   "metadata": {
    "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20170d89-85a0-4844-9887-832f5d23432a",
   "metadata": {},
   "source": [
    "- Next, we use the dataset to instantiate the data loaders, which is similar to creating the data loaders in previous chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcc349-205f-48f8-9655-95ff21f5e72f",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/batch.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
    "outputId": "3266c410-4fdb-4a8c-a142-7f707e2525ab"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {},
   "source": [
    "- As a verification step, we iterate through the data loaders and ensure that the batches contain 8 training examples each, where each training example consists of 120 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {},
   "source": [
    "- Lastly, let's print the total number of batches in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "6934bbf2-9797-4fbe-d26b-1a246e18c2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c",
   "metadata": {
    "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c"
   },
   "source": [
    "## 6.4 Initializing a model with pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208",
   "metadata": {},
   "source": [
    "- In this section, we initialize the pretrained model we worked with in the previous chapter\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-2.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
   "metadata": {
    "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "022a649a-44f5-466c-8a8e-326c063384f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "022a649a-44f5-466c-8a8e-326c063384f5",
    "outputId": "7091e401-8442-4f47-a1d9-ecb42a1ef930"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|ââââââââââ| 77.0/77.0 [00:00<00:00, 11.7kiB/s]\n",
      "encoder.json: 100%|ââââââââââ| 1.04M/1.04M [00:00<00:00, 2.42MiB/s]\n",
      "hparams.json: 100%|ââââââââââ| 90.0/90.0 [00:00<?, ?iB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|ââââââââââ| 498M/498M [00:24<00:00, 20.0MiB/s] \n",
      "model.ckpt.index: 100%|ââââââââââ| 5.21k/5.21k [00:00<00:00, 2.59MiB/s]\n",
      "model.ckpt.meta: 100%|ââââââââââ| 471k/471k [00:00<00:00, 742kiB/s] \n",
      "vocab.bpe: 100%|ââââââââââ| 456k/456k [00:00<00:00, 863kiB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "# If the `previous_chapters.py` file is not available locally,\n",
    "# you can import it from the `llms-from-scratch` PyPI package.\n",
    "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "# E.g.,\n",
    "# from llms_from_scratch.ch04 import GPTModel\n",
    "# from llms_from_scratch.ch05 import download_and_load_gpt2, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e056c-abe0-415f-b34d-df686204259e",
   "metadata": {},
   "source": [
    "- To ensure that the model was loaded correctly, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch05 import (\n",
    "#    generate_text_simple,\n",
    "#    text_to_token_ids,\n",
    "#    token_ids_to_text\n",
    "# )\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69162550-6a02-4ece-8db1-06c71d61946f",
   "metadata": {},
   "source": [
    "- Before we finetune the model as a classifier, let's see if the model can perhaps already classify spam messages via prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016",
   "metadata": {},
   "source": [
    "- As we can see, the model is not very good at following instructions\n",
    "- This is expected, since it has only been pretrained and not instruction-finetuned (instruction finetuning will be covered in the next chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522",
   "metadata": {
    "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522"
   },
   "source": [
    "## 6.5 Adding a classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/lm-head.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217bac05-78df-4412-bd80-612f8061c01d",
   "metadata": {},
   "source": [
    "- In this section, we are modifying the pretrained LLM to make it ready for classification finetuning\n",
    "- Let's take a look at the model architecture first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d8f7a01-b7c0-48d4-b1e7-8c12cc7ad932",
    "outputId": "b6a5b9b5-a92f-498f-d7cb-b58dd99e4497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d",
   "metadata": {},
   "source": [
    "- Above, we can see the architecture we implemented in chapter 4 neatly laid out\n",
    "- The goal is to replace and finetune the output layer\n",
    "- To achieve this, we first freeze the model, meaning that we make all layers non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fkMWFl-0etea",
   "metadata": {
    "id": "fkMWFl-0etea"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72155f83-87d9-476a-a978-a15aa2d44147",
   "metadata": {},
   "source": [
    "- Then, we replace the output layer (`model.out_head`), which originally maps the layer inputs to 50,257 dimensions (the size of the vocabulary)\n",
    "- Since we finetune the model for binary classification (predicting 2 classes, \"spam\" and \"not spam\"), we can replace the output layer as shown below, which will be trainable by default\n",
    "- Note that we use `BASE_CONFIG[\"emb_dim\"]` (which is equal to 768 in the `\"gpt2-small (124M)\"` model) to keep the code below more general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be5475-ae77-4f97-8f3e-dec462b1339f",
   "metadata": {},
   "source": [
    "- Technically, it's sufficient to only train the output layer\n",
    "- However, as I found in [Finetuning Large Language Models](https://magazine.sebastianraschka.com/p/finetuning-large-language-models), experiments show that finetuning additional layers can noticeably improve the performance\n",
    "- So, we are also making the last transformer block and the final `LayerNorm` module connecting the last transformer block to the output layer trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/trainable.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
   "metadata": {
    "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
   },
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e",
   "metadata": {},
   "source": [
    "- We can still use this model similar to before in previous chapters\n",
    "- For example, let's feed it some text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
    "outputId": "27e041b1-d731-48a1-cf60-f22d4565304e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b",
   "metadata": {},
   "source": [
    "- What's different compared to previous chapters is that it now has two output dimensions instead of 50,257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
    "outputId": "9cae7448-253d-4776-973e-0af190b06354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75430a01-ef9c-426a-aca0-664689c4f461",
   "metadata": {},
   "source": [
    "- As discussed in previous chapters, for each input token, there's one output vector\n",
    "- Since we fed the model a text sample with 4 input tokens, the output consists of 4 2-dimensional output vectors above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/input-and-output.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a",
   "metadata": {},
   "source": [
    "- In chapter 3, we discussed the attention mechanism, which connects each input token to each other input token\n",
    "- In chapter 3, we then also introduced the causal attention mask that is used in GPT-like models; this causal mask lets a current token only attend to the current and previous token positions\n",
    "- **Based on this causal attention mechanism, the 4th (last) token contains the most information among all tokens because it's the only token that includes information about all other tokens**\n",
    "- Hence, we are particularly interested in this last token, which we will finetune for the spam classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
    "outputId": "e79eb155-fa1f-46ed-ff8c-d828c3a3fabd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/attention-mask.webp\" width=200px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c",
   "metadata": {},
   "source": [
    "## 6.6 Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-3.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3",
   "metadata": {},
   "source": [
    "- Before explaining the loss calculation, let's have a brief look at how the model outputs are turned into class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/class-argmax.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c77faab1-3461-4118-866a-6171f2b89aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we convert the outputs (logits) into probability scores via the `softmax` function and then obtain the index position of the largest probability value via the `argmax` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a6f02-307e-4147-a416-14d115bf8179",
   "metadata": {},
   "source": [
    "- Note that the softmax function is optional here, as explained in chapter 5, because the largest outputs correspond to the largest probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505",
   "metadata": {},
   "source": [
    "- We can apply this concept to calculate the so-called classification accuracy, which computes the percentage of correct predictions in a given dataset\n",
    "- To calculate the classification accuracy, we can apply the preceding `argmax`-based prediction code to all examples in a dataset and calculate the fraction of correct predictions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165fe46-a284-410b-957f-7524877d1a1a",
   "metadata": {},
   "source": [
    "- Let's apply the function to calculate the classification accuracies for the different datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda device.\n",
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "print(f\"Running on {device} device.\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30345e2a-afed-4d22-9486-f4010f90a871",
   "metadata": {},
   "source": [
    "- As we can see, the prediction accuracies are not very good, since we haven't finetuned the model, yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328",
   "metadata": {},
   "source": [
    "- Before we can start finetuning (/training), we first have to define the loss function we want to optimize during training\n",
    "- The goal is to maximize the spam classification accuracy of the model; however, classification accuracy is not a differentiable function\n",
    "- Hence, instead, we minimize the cross-entropy loss as a proxy for maximizing the classification accuracy (you can learn more about this topic in lecture 8 of my freely available [Introduction to Deep Learning](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression) class)\n",
    "\n",
    "- The `calc_loss_batch` function is the same here as in chapter 5, except that we are only interested in optimizing the last token `model(input_batch)[:, -1, :]` instead of all tokens `model(input_batch)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
   "metadata": {
    "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
   "metadata": {},
   "source": [
    "The `calc_loss_loader` is exactly the same as in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56826ecd-6e74-40e6-b772-d3541e585067",
   "metadata": {},
   "source": [
    "- Using the `calc_closs_loader`, we compute the initial training, validation, and test set losses before we start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
    "outputId": "49df8648-9e38-4314-854d-9faacd1b2e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d",
   "metadata": {},
   "source": [
    "- In the next section, we train the model to improve the loss values and consequently the classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ae0fd-6261-42b4-ab6a-d24289953083",
   "metadata": {
    "id": "456ae0fd-6261-42b4-ab6a-d24289953083"
   },
   "source": [
    "## 6.7 Finetuning the model on supervised data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b099b-0829-4f72-8a2b-4363e3497026",
   "metadata": {},
   "source": [
    "- In this section, we define and use the training function to improve the classification accuracy of the model\n",
    "- The `train_classifier_simple` function below is practically the same as the `train_model_simple` function we used for pretraining the model in chapter 5\n",
    "- The only two differences are that we now \n",
    "  1. track the number of training examples seen (`examples_seen`) instead of the number of tokens seen\n",
    "  2. calculate the accuracy after each epoch instead of printing a sample text after each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/training-loop.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "Csbr60to50FL",
   "metadata": {
    "id": "Csbr60to50FL"
   },
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624cb30-3e3a-45be-b006-c00475b58ae8",
   "metadata": {},
   "source": [
    "- The `evaluate_model` function used in the `train_classifier_simple` is the same as the one we used in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9",
   "metadata": {},
   "source": [
    "- The training takes about 5 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "X7kU3aAj7vTJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7kU3aAj7vTJ",
    "outputId": "504a033e-2bf8-41b5-a037-468309845513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.884, Val loss 2.596\n",
      "Ep 1 (Step 000050): Train loss 0.293, Val loss 0.190\n",
      "Ep 1 (Step 000100): Train loss 0.148, Val loss 0.501\n",
      "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
      "Ep 2 (Step 000150): Train loss 0.162, Val loss 0.073\n",
      "Ep 2 (Step 000200): Train loss 0.004, Val loss 0.029\n",
      "Ep 2 (Step 000250): Train loss 0.028, Val loss 0.103\n",
      "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
      "Ep 3 (Step 000300): Train loss 0.010, Val loss 0.127\n",
      "Ep 3 (Step 000350): Train loss 0.001, Val loss 0.009\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 4 (Step 000400): Train loss 0.005, Val loss 0.006\n",
      "Ep 4 (Step 000450): Train loss 0.008, Val loss 0.020\n",
      "Ep 4 (Step 000500): Train loss 0.001, Val loss 0.114\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 5 (Step 000550): Train loss 0.031, Val loss 0.021\n",
      "Ep 5 (Step 000600): Train loss 0.002, Val loss 0.090\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Training completed in 0.58 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261bf90-3ce7-4591-895a-044a05538f30",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we use matplotlib to plot the loss function for the training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cURgnDqdCeka",
   "metadata": {
    "id": "cURgnDqdCeka"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "OIqRt466DiGk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "OIqRt466DiGk",
    "outputId": "b16987cf-0001-4652-ddaf-02f7cffc34db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc",
   "metadata": {},
   "source": [
    "- Above, based on the downward slope, we see that the model learns well\n",
    "- Furthermore, the fact that the training and validation loss are very close indicates that the model does not tend to overfit the training data\n",
    "- Similarly, we can plot the accuracy below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "yz8BIsaF0TUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "yz8BIsaF0TUo",
    "outputId": "3a7ed967-1f2a-4c6d-f4a3-0cc8cc9d6c5f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aba699-21bc-42de-a69c-99f370bb0363",
   "metadata": {},
   "source": [
    "- Based on the accuracy plot above, we can see that the model achieves a relatively high training and validation accuracy after epochs 4 and 5\n",
    "- However, we have to keep in mind that we specified `eval_iter=5` in the training function earlier, which means that we only estimated the training and validation set performances\n",
    "- We can compute the training, validation, and test set performances over the complete dataset as follows below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "UHWaJFrjY0zW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHWaJFrjY0zW",
    "outputId": "e111e6e6-b147-4159-eb9d-19d4e809ed34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.23%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 94.33%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882649f-dc7b-401f-84d2-024ff79c74a1",
   "metadata": {},
   "source": [
    "- We can see that the training and validation set performances are practically identical\n",
    "- However, based on the slightly lower test set performance, we can see that the model overfits the training data to a very small degree, as well as the validation data that has been used for tweaking some of the hyperparameters, such as the learning rate\n",
    "- This is normal, however, and this gap could potentially be further reduced by increasing the model's dropout rate (`drop_rate`) or the `weight_decay` in the optimizer setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0",
   "metadata": {},
   "source": [
    "## 6.8 Using the LLM as a spam classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebcfa2-479e-408b-9cf0-7421f6144855",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-4.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
   "metadata": {},
   "source": [
    "- Finally, let's use the finetuned GPT model in action\n",
    "- The `classify_review` function below implements the data preprocessing steps similar to the `SpamDataset` we implemented earlier\n",
    "- Then, the function returns the predicted integer class label from the model and returns the corresponding class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aHdn6xvL-IW5",
   "metadata": {
    "id": "aHdn6xvL-IW5"
   },
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "    assert max_length is not None, (\n",
    "        \"max_length must be specified. If you want to use the full model context, \"\n",
    "        \"pass max_length=model.pos_emb.weight.shape[0].\"\n",
    "    )\n",
    "    assert max_length <= supported_context_length, (\n",
    "        f\"max_length ({max_length}) exceeds model's supported context length ({supported_context_length}).\"\n",
    "    )    \n",
    "    # Alternatively, a more robust version is the following one, which handles the max_length=None case better\n",
    "    # max_len = min(max_length,supported_context_length) if max_length else supported_context_length\n",
    "    # input_ids = input_ids[:max_len]\n",
    "    \n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
   "metadata": {},
   "source": [
    "- Let's try it out on a few examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "apU_pf51AWSV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apU_pf51AWSV",
    "outputId": "d0fde0a5-e7a3-4dbe-d9c5-0567dbab7e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1g5VTOo_Ajs5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1g5VTOo_Ajs5",
    "outputId": "659b08eb-b6a9-4a8a-9af7-d94c757e93c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
   "metadata": {},
   "source": [
    "- Finally, let's save the model in case we want to reuse the model later without having to train it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "mYnX-gI1CfQY",
   "metadata": {
    "id": "mYnX-gI1CfQY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
   "metadata": {},
   "source": [
    "- Then, in a new session, we could load the model as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4",
   "metadata": {
    "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4"
   },
   "source": [
    "## Summary and takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
   "metadata": {},
   "source": [
    "- See the [./gpt_class_finetune.py](./gpt_class_finetune.py) script, a self-contained script for classification finetuning\n",
    "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)\n",
    "- In addition, interested readers can find an introduction to parameter-efficient training with low-rank adaptation (LoRA) in [appendix E](../../appendix-E)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llm_t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
